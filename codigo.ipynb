{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Banco de Dados"
      ],
      "metadata": {
        "id": "UclvUkmTmaIZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Xo8pMCd5OW",
        "outputId": "728b3f6f-811a-4707-f1cc-5563e964258a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a download option:\n",
            "1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)\n",
            "2) Kuzushiji-49 (49 classes, 28x28, 270k examples)\n",
            "3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)\n",
            "> 1\n",
            "Please select a download option:\n",
            "1) MNIST data format (ubyte.gz)\n",
            "2) NumPy data format (.npz)\n",
            "> 2\n",
            "Downloading kmnist-train-imgs.npz - 18.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17954/17954 [00:05<00:00, 3505.87KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-train-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 767.83KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-test-imgs.npz - 3.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3008/3008 [00:01<00:00, 2522.80KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kmnist-test-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 8047.91KB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    tqdm = lambda x, total, unit: x  # If tqdm doesn't exist, replace it with a function that does nothing\n",
        "    print('**** Could not import tqdm. Please install tqdm for download progressbars! (pip install tqdm) ****')\n",
        "\n",
        "# Python2 compatibility\n",
        "try:\n",
        "    input = raw_input\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "download_dict = {\n",
        "    '1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)': {\n",
        "        '1) MNIST data format (ubyte.gz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'],\n",
        "        '2) NumPy data format (.npz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'],\n",
        "    },\n",
        "    '2) Kuzushiji-49 (49 classes, 28x28, 270k examples)': {\n",
        "        '1) NumPy data format (.npz)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
        "    },\n",
        "    '3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)': {\n",
        "        '1) Folders of images (.tar)':\n",
        "            ['http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar'],\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Download a list of files\n",
        "def download_list(url_list):\n",
        "    for url in url_list:\n",
        "        path = url.split('/')[-1]\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            total_length = int(r.headers.get('content-length'))\n",
        "            print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "\n",
        "            for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    print('All dataset files downloaded!')\n",
        "\n",
        "# Ask the user about which path to take down the dict\n",
        "def traverse_dict(d):\n",
        "    print('Please select a download option:')\n",
        "    keys = sorted(d.keys())  # Print download options\n",
        "    for key in keys:\n",
        "        print(key)\n",
        "\n",
        "    userinput = input('> ').strip()\n",
        "\n",
        "    try:\n",
        "        selection = int(userinput) - 1\n",
        "    except ValueError:\n",
        "        print('Your selection was not valid')\n",
        "        traverse_dict(d)  # Try again if input was not valid\n",
        "        return\n",
        "\n",
        "    selected = keys[selection]\n",
        "\n",
        "    next_level = d[selected]\n",
        "    if isinstance(next_level, list):  # If we've hit a list of downloads, download that list\n",
        "        download_list(next_level)\n",
        "    else:\n",
        "        traverse_dict(next_level)     # Otherwise, repeat with the next level\n",
        "\n",
        "traverse_dict(download_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baixar BD"
      ],
      "metadata": {
        "id": "bRx50OjUmj4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "AX = np.load(\"kmnist-train-imgs.npz\")['arr_0']\n",
        "AY = np.load(\"kmnist-train-labels.npz\")['arr_0']\n",
        "QX = np.load(\"kmnist-test-imgs.npz\")['arr_0']\n",
        "QY = np.load(\"kmnist-test-labels.npz\")['arr_0']\n"
      ],
      "metadata": {
        "id": "ni2UhunhecFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolucional"
      ],
      "metadata": {
        "id": "IJ87YwzZmqCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn1.py - pos2021\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np; import sys; import os; from time import time\n",
        "AX=255-AX; QX=255-QX\n",
        "\n",
        "nclasses = 10\n",
        "nl, nc = AX.shape[1], AX.shape[2] #28, 28\n",
        "AX = (AX.astype('float32') / 255.0)-0.5 # -0.5 a +0.5\n",
        "QX = (QX.astype('float32') / 255.0)-0.5 # -0.5 a +0.5\n",
        "AX = np.expand_dims(AX,axis=3) # AX [60000,28,28,1]\n",
        "QX = np.expand_dims(QX,axis=3)\n",
        "model = Sequential() # 28x28\n",
        "model.add(Conv2D(20, kernel_size=(5,5), activation='relu',\n",
        " input_shape=(nl, nc, 1) )) #20x24x24\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #20x12x12\n",
        "model.add(Conv2D(40, kernel_size=(5,5), activation='relu')) #40x8x8\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #40x4x4\n",
        "model.add(Flatten()) #640\n",
        "model.add(Dense(200, activation='relu')) #200\n",
        "model.add(Dense(nclasses, activation='softmax')) #10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='cnn1.png', show_shapes=True);\n",
        "model.summary()\n",
        "opt=optimizers.Adam()\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "t0=time()\n",
        "model.fit(AX, AY, batch_size=100, epochs=30, verbose=2)\n",
        "t1=time(); print(\"Tempo de treino: %.2f s\"%(t1-t0))\n",
        "score = model.evaluate(QX, QY, verbose=False)\n",
        "print('Test loss: %.4f'%(score[0]))\n",
        "print('Test accuracy: %.2f %%'%(100*score[1]))\n",
        "print('Test error: %.2f %%'%(100*(1-score[1])))\n",
        "t2=time()\n",
        "QP2=model.predict(QX); QP=np.argmax(QP2,1)\n",
        "t3=time(); print(\"Tempo de predicao: %.2f s\"%(t3-t2))\n",
        "nerro=np.count_nonzero(QP-QY); print(\"nerro=%d\"%(nerro))\n",
        "model.save('cnn1.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezbDFaI8f4bB",
        "outputId": "754df617-d468-4cd5-9ea8-35c43113c5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 20)        520       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 20)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 40)          20040     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 40)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 640)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               128200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 150,770\n",
            "Trainable params: 150,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "600/600 - 14s - loss: 0.3732 - accuracy: 0.8844 - 14s/epoch - 24ms/step\n",
            "Epoch 2/30\n",
            "600/600 - 2s - loss: 0.1056 - accuracy: 0.9683 - 2s/epoch - 3ms/step\n",
            "Epoch 3/30\n",
            "600/600 - 2s - loss: 0.0651 - accuracy: 0.9805 - 2s/epoch - 3ms/step\n",
            "Epoch 4/30\n",
            "600/600 - 2s - loss: 0.0440 - accuracy: 0.9873 - 2s/epoch - 4ms/step\n",
            "Epoch 5/30\n",
            "600/600 - 2s - loss: 0.0316 - accuracy: 0.9904 - 2s/epoch - 3ms/step\n",
            "Epoch 6/30\n",
            "600/600 - 2s - loss: 0.0228 - accuracy: 0.9932 - 2s/epoch - 3ms/step\n",
            "Epoch 7/30\n",
            "600/600 - 2s - loss: 0.0187 - accuracy: 0.9939 - 2s/epoch - 3ms/step\n",
            "Epoch 8/30\n",
            "600/600 - 2s - loss: 0.0136 - accuracy: 0.9957 - 2s/epoch - 3ms/step\n",
            "Epoch 9/30\n",
            "600/600 - 2s - loss: 0.0130 - accuracy: 0.9961 - 2s/epoch - 3ms/step\n",
            "Epoch 10/30\n",
            "600/600 - 2s - loss: 0.0080 - accuracy: 0.9975 - 2s/epoch - 3ms/step\n",
            "Epoch 11/30\n",
            "600/600 - 2s - loss: 0.0115 - accuracy: 0.9960 - 2s/epoch - 4ms/step\n",
            "Epoch 12/30\n",
            "600/600 - 2s - loss: 0.0073 - accuracy: 0.9977 - 2s/epoch - 3ms/step\n",
            "Epoch 13/30\n",
            "600/600 - 2s - loss: 0.0075 - accuracy: 0.9975 - 2s/epoch - 3ms/step\n",
            "Epoch 14/30\n",
            "600/600 - 2s - loss: 0.0086 - accuracy: 0.9969 - 2s/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "600/600 - 2s - loss: 0.0053 - accuracy: 0.9983 - 2s/epoch - 3ms/step\n",
            "Epoch 16/30\n",
            "600/600 - 2s - loss: 0.0049 - accuracy: 0.9984 - 2s/epoch - 3ms/step\n",
            "Epoch 17/30\n",
            "600/600 - 2s - loss: 0.0069 - accuracy: 0.9979 - 2s/epoch - 3ms/step\n",
            "Epoch 18/30\n",
            "600/600 - 2s - loss: 0.0088 - accuracy: 0.9971 - 2s/epoch - 4ms/step\n",
            "Epoch 19/30\n",
            "600/600 - 2s - loss: 0.0033 - accuracy: 0.9988 - 2s/epoch - 3ms/step\n",
            "Epoch 20/30\n",
            "600/600 - 2s - loss: 0.0039 - accuracy: 0.9988 - 2s/epoch - 3ms/step\n",
            "Epoch 21/30\n",
            "600/600 - 2s - loss: 0.0063 - accuracy: 0.9981 - 2s/epoch - 3ms/step\n",
            "Epoch 22/30\n",
            "600/600 - 2s - loss: 0.0059 - accuracy: 0.9981 - 2s/epoch - 3ms/step\n",
            "Epoch 23/30\n",
            "600/600 - 2s - loss: 0.0041 - accuracy: 0.9986 - 2s/epoch - 3ms/step\n",
            "Epoch 24/30\n",
            "600/600 - 2s - loss: 0.0059 - accuracy: 0.9982 - 2s/epoch - 4ms/step\n",
            "Epoch 25/30\n",
            "600/600 - 2s - loss: 0.0034 - accuracy: 0.9989 - 2s/epoch - 3ms/step\n",
            "Epoch 26/30\n",
            "600/600 - 2s - loss: 0.0011 - accuracy: 0.9997 - 2s/epoch - 3ms/step\n",
            "Epoch 27/30\n",
            "600/600 - 2s - loss: 7.6888e-05 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Epoch 28/30\n",
            "600/600 - 2s - loss: 1.8906e-05 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Epoch 29/30\n",
            "600/600 - 2s - loss: 1.2144e-05 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Epoch 30/30\n",
            "600/600 - 2s - loss: 9.0249e-06 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Tempo de treino: 66.63 s\n",
            "Test loss: 0.3393\n",
            "Test accuracy: 96.10 %\n",
            "Test error: 3.90 %\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Tempo de predicao: 0.88 s\n",
            "nerro=390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baixar BD"
      ],
      "metadata": {
        "id": "tBH5d5Uzm4Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "AX = np.load(\"kmnist-train-imgs.npz\")['arr_0']\n",
        "AY = np.load(\"kmnist-train-labels.npz\")['arr_0']\n",
        "QX = np.load(\"kmnist-test-imgs.npz\")['arr_0']\n",
        "QY = np.load(\"kmnist-test-labels.npz\")['arr_0']\n"
      ],
      "metadata": {
        "id": "k-biDkpqlM_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes nerauis densa"
      ],
      "metadata": {
        "id": "JnEGVF-Km6yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp1.py\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Normalization\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np; import sys\n",
        "AX=255-AX; QX=255-QX\n",
        "nclasses = 10\n",
        "nl, nc = AX.shape[1], AX.shape[2] #28, 28\n",
        "#Pseudo-normalizacao\n",
        "#AX = (AX.astype('float32')/255.0)-0.5 # -0.5 a +0.5\n",
        "#QX = (QX.astype('float32')/255.0)-0.5 # -0.5 a +0.5\n",
        "#Normalizacao1 - distribuicao normal de media zero e desvio 1\n",
        "#media=np.mean(AX); desvio=np.std(AX)\n",
        "#AX=AX.astype('float32'); AX=AX-media; AX=AX/desvio; QX=QX.astype('float32'); QX=QX-media; QX=QX/desvio\n",
        "#Normalizacao2 - inserir camada de normalizacao na rede\n",
        "model = Sequential()\n",
        "model.add(Normalization(input_shape=(nl,nc))) #Normaliza\n",
        "model.add(Flatten())\n",
        "model.add(Dense(400, activation='sigmoid'))\n",
        "model.add(Dense(nclasses, activation='sigmoid'))\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='mlp1.png', show_shapes=True)\n",
        "model.summary()\n",
        "opt=optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.get_layer(index=0).adapt(AX) #Calcula media e desvio\n",
        "model.fit(AX, AY, batch_size=100, epochs=40, verbose=2)\n",
        "score = model.evaluate(QX, QY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save('mlp1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY44gUH0lBMk",
        "outputId": "9c1e215b-5f84-493a-fa51-47de576137ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_2 (Normalizat  (None, 28, 28)           57        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 400)               314000    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 318,067\n",
            "Trainable params: 318,010\n",
            "Non-trainable params: 57\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "600/600 - 2s - loss: 0.6159 - accuracy: 0.8194 - 2s/epoch - 3ms/step\n",
            "Epoch 2/40\n",
            "600/600 - 1s - loss: 0.3714 - accuracy: 0.8935 - 1s/epoch - 2ms/step\n",
            "Epoch 3/40\n",
            "600/600 - 1s - loss: 0.2719 - accuracy: 0.9245 - 1s/epoch - 2ms/step\n",
            "Epoch 4/40\n",
            "600/600 - 1s - loss: 0.2095 - accuracy: 0.9454 - 1s/epoch - 2ms/step\n",
            "Epoch 5/40\n",
            "600/600 - 1s - loss: 0.1654 - accuracy: 0.9583 - 1s/epoch - 2ms/step\n",
            "Epoch 6/40\n",
            "600/600 - 1s - loss: 0.1326 - accuracy: 0.9685 - 1s/epoch - 2ms/step\n",
            "Epoch 7/40\n",
            "600/600 - 2s - loss: 0.1071 - accuracy: 0.9758 - 2s/epoch - 3ms/step\n",
            "Epoch 8/40\n",
            "600/600 - 1s - loss: 0.0866 - accuracy: 0.9822 - 1s/epoch - 2ms/step\n",
            "Epoch 9/40\n",
            "600/600 - 1s - loss: 0.0694 - accuracy: 0.9873 - 1s/epoch - 2ms/step\n",
            "Epoch 10/40\n",
            "600/600 - 1s - loss: 0.0557 - accuracy: 0.9908 - 1s/epoch - 2ms/step\n",
            "Epoch 11/40\n",
            "600/600 - 1s - loss: 0.0446 - accuracy: 0.9938 - 1s/epoch - 2ms/step\n",
            "Epoch 12/40\n",
            "600/600 - 1s - loss: 0.0357 - accuracy: 0.9961 - 1s/epoch - 2ms/step\n",
            "Epoch 13/40\n",
            "600/600 - 1s - loss: 0.0284 - accuracy: 0.9971 - 1s/epoch - 2ms/step\n",
            "Epoch 14/40\n",
            "600/600 - 1s - loss: 0.0223 - accuracy: 0.9983 - 1s/epoch - 2ms/step\n",
            "Epoch 15/40\n",
            "600/600 - 1s - loss: 0.0174 - accuracy: 0.9989 - 1s/epoch - 2ms/step\n",
            "Epoch 16/40\n",
            "600/600 - 1s - loss: 0.0140 - accuracy: 0.9993 - 1s/epoch - 2ms/step\n",
            "Epoch 17/40\n",
            "600/600 - 2s - loss: 0.0108 - accuracy: 0.9997 - 2s/epoch - 3ms/step\n",
            "Epoch 18/40\n",
            "600/600 - 1s - loss: 0.0084 - accuracy: 0.9998 - 1s/epoch - 2ms/step\n",
            "Epoch 19/40\n",
            "600/600 - 1s - loss: 0.0066 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 20/40\n",
            "600/600 - 1s - loss: 0.0052 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 21/40\n",
            "600/600 - 1s - loss: 0.0040 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 22/40\n",
            "600/600 - 1s - loss: 0.0031 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 23/40\n",
            "600/600 - 1s - loss: 0.0026 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 24/40\n",
            "600/600 - 1s - loss: 0.0020 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 25/40\n",
            "600/600 - 1s - loss: 0.0015 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 26/40\n",
            "600/600 - 1s - loss: 0.0012 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 27/40\n",
            "600/600 - 2s - loss: 9.4804e-04 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Epoch 28/40\n",
            "600/600 - 1s - loss: 7.8106e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 29/40\n",
            "600/600 - 1s - loss: 5.8819e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 30/40\n",
            "600/600 - 1s - loss: 0.0024 - accuracy: 0.9994 - 1s/epoch - 2ms/step\n",
            "Epoch 31/40\n",
            "600/600 - 1s - loss: 0.0024 - accuracy: 0.9996 - 1s/epoch - 2ms/step\n",
            "Epoch 32/40\n",
            "600/600 - 1s - loss: 4.9361e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 33/40\n",
            "600/600 - 1s - loss: 3.7733e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 34/40\n",
            "600/600 - 1s - loss: 3.1903e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 35/40\n",
            "600/600 - 1s - loss: 2.7655e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 36/40\n",
            "600/600 - 1s - loss: 2.3935e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 37/40\n",
            "600/600 - 2s - loss: 2.0769e-04 - accuracy: 1.0000 - 2s/epoch - 3ms/step\n",
            "Epoch 38/40\n",
            "600/600 - 1s - loss: 1.7959e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 39/40\n",
            "600/600 - 1s - loss: 1.5299e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Epoch 40/40\n",
            "600/600 - 1s - loss: 1.2924e-04 - accuracy: 1.0000 - 1s/epoch - 2ms/step\n",
            "Test loss: 0.4989689886569977\n",
            "Test accuracy: 0.9017999768257141\n"
          ]
        }
      ]
    }
  ]
}